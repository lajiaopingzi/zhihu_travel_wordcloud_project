{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b420bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# initialization if you don't have followed packages\n",
    "# !pip install jieba\n",
    "# !pip install wordcloud\n",
    "# !pip insrall collections\n",
    "\n",
    "import jieba\n",
    "import numpy as np\n",
    "import random\n",
    "import jieba.analyse as anls\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142dd75",
   "metadata": {},
   "source": [
    "# Crawl Zhihu travel column content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zhuanlan_url = ['c_114424127','ethanlam','c_134036341','zhoumolvxing','xiyougogo','c_1158068494032707584','c_1199019869133549568','c_1213818120634560512','c_190409180','Ge-Song','lanyanjing','c_1333313310423724032','c_152002793','c_1327315626012880896','c_1365632380191969280','lushuvip','c_176462911','beshan','huangjianhua','c_1277310537517756416']\n",
    "zhuanlan_names = ['旅行','一群旅行体验师','旅行记','周末旅行','嬉游-旅行其实很简单','研学旅行','旅行','旅行','in旅行','环球旅行杂谈','世界旅行清单','国内旅行','富龙旅行','旅行','自驾旅行','走进旅行定制师','旅行头条','碧山旅行','旅行世界','旅行']\n",
    "zhuanlan = 0  # The initial number of columns to start crawling\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'}\n",
    "\n",
    "# Define methods to write data to csv documents\n",
    "def write_file(records):\n",
    "    # Determines if the file already exists locally\n",
    "    file_exists = os.path.isfile('zhihu_data.csv')\n",
    "    with open('zhihu_data.csv', mode='a' if file_exists else 'w', newline='', encoding='gb18030') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"column_num\",\"column_name\", \"title\",\"approval_num\", \"comments_num\",\"link\", \"create_date\",\"update_date\", \"author_name\",\"author_sex\", \"author_id\",\"type\"])\n",
    "        for item in records:\n",
    "            row = [item[\"order\"],item[\"zhuanlan_name\"], item[\"title\"],item[\"voteup_count\"], item[\"comment_count\"],item[\"url\"], item[\"created\"],item[\"updated\"], item[\"author\"],item[\"author_gender\"], item[\"author_uid\"],item[\"ptype\"]]\n",
    "            writer.writerow(row)     \n",
    "    print(\"此次共爬取保存{}条数据\".format(len(records)))\n",
    "    \n",
    "def get_zhihu_json(url):\n",
    "    res = requests.get(url, headers = headers)\n",
    "    #print(res)\n",
    "    soup=BeautifulSoup(res.text, 'html.parser')\n",
    "    json_data = res.json()\n",
    "    return json_data\n",
    "\n",
    "for group in zhuanlan_url:\n",
    "    records = []  # record the crawled data\n",
    "    pages = 1     # By default, 1 page is crawled\n",
    "    limit = 100   # Each request fetches 100 pieces of data\n",
    "    offset = 0\n",
    "    url = 'https://www.zhihu.com/api/v4/columns/' + group + '/items?'\n",
    "    json_data = get_zhihu_json(url)\n",
    "    data_totals = json_data[\"paging\"][\"totals\"]    # Get the total number of entries in each column\n",
    "    print(\"begin crawl the zhuanlan of \"+zhuanlan_names[zhuanlan]+\" : which have \" +str(data_totals)+\" articles.\")\n",
    "    pages = (data_totals // 100)+1  \n",
    "        \n",
    "    for page in range(pages):  # Paginate for crawling\n",
    "        next_url = 'https://www.zhihu.com/api/v4/columns/' + group + '/items?limit=' + str(limit) + f'&offset={page*100}'\n",
    "        #print(\"begin crawl page \" +str(page)+\" : \"+str(next_url))\n",
    "        json_data = get_zhihu_json(next_url)\n",
    "        for i in range(len(json_data[\"data\"])):\n",
    "            zhuanlan_name = zhuanlan_names[zhuanlan]   # Column name\n",
    "            if json_data[\"data\"][i][\"type\"]==\"article\":\n",
    "                title = json_data[\"data\"][i][\"title\"]   # title\n",
    "                voteup_count = json_data[\"data\"][i][\"voteup_count\"]   # Number of endorsements\n",
    "                comment_count = json_data[\"data\"][i][\"comment_count\"]   # Number of comment\n",
    "                url = json_data[\"data\"][i][\"url\"]   # link\n",
    "                created = json_data[\"data\"][i][\"created\"]   # Creation time\n",
    "                updated = json_data[\"data\"][i][\"updated\"]   # Last updated time\n",
    "                author = json_data[\"data\"][i][\"author\"][\"name\"]   # author name\n",
    "                author_gender = json_data[\"data\"][i][\"author\"][\"gender\"]   # author gender\n",
    "                author_uid = json_data[\"data\"][i][\"author\"][\"uid\"]   # author id\n",
    "            if json_data[\"data\"][i][\"type\"]==\"answer\":\n",
    "                title = json_data[\"data\"][i][\"question\"][\"title\"]   # title\n",
    "                voteup_count = json_data[\"data\"][i][\"voteup_count\"]   # Number of endorsements\n",
    "                comment_count = json_data[\"data\"][i][\"comment_count\"]   # Number of comment\n",
    "                url = \"/\"   # link\n",
    "                created = json_data[\"data\"][i][\"created_time\"]   # creation time\n",
    "                updated = json_data[\"data\"][i][\"updated_time\"]   # Number of comment\n",
    "                author = json_data[\"data\"][i][\"author\"][\"name\"]  # author name\n",
    "                author_gender = json_data[\"data\"][i][\"author\"][\"gender\"]  # author gender\n",
    "                author_uid = json_data[\"data\"][i][\"author\"][\"uid\"]   # author id\n",
    "            ptype = json_data[\"data\"][i][\"type\"]\n",
    "            records.append({\"order\":zhuanlan,\"zhuanlan_name\":zhuanlan_name,\"title\":title,\"voteup_count\":voteup_count, \"comment_count\":comment_count,\"url\":url,\"created\":created,\"updated\":updated, \"author\":author,\"author_gender\":author_gender,\"author_uid\":author_uid,\"ptype\":ptype})\n",
    "        time.sleep(2)  # Control the crawling speed to prevent being blocked by the site\n",
    "    zhuanlan += 1\n",
    "    write_file(records)\n",
    "    time.sleep(10)  # Control the crawling speed to prevent being blocked by the site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ae1fe",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files generated by the crawler and process the data\n",
    "df = pd.read_csv('zhihu_data.csv',encoding='gb18030')\n",
    "\n",
    "# Converts numeric dates to year, month, and day format\n",
    "df['创建日期'] = pd.to_datetime(df['创建日期'], unit='s').dt.strftime('%d/%m/%Y')\n",
    "df['更新日期'] = pd.to_datetime(df['更新日期'], unit='s').dt.strftime('%d/%m/%Y')\n",
    "df['作者性别'] = df['作者性别'].map({1: '男', 0: '女'})\n",
    "\n",
    "# Write the processed data back to the zhihu_data.csv file\n",
    "df.to_csv('zhihu_data.csv', index=False, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951199a5",
   "metadata": {},
   "source": [
    "# Key words extraction and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e211b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename,sep=',',header=0)\n",
    "    data = data.iloc[:, [0,1,2,6,8]]\n",
    "    columns = data.iloc[:,1].unique()\n",
    "    columns = np.append(columns, 'all')\n",
    "    lenCol = len(columns)\n",
    "    \n",
    "    data.iloc[:, 3] = data.iloc[:, 3].str.split('/').str[-1]\n",
    "    year = data.iloc[:, 3].unique()\n",
    "    lenY = len(year)\n",
    "    \n",
    "    authors = data.iloc[:,4].unique()\n",
    "    res_col = {}\n",
    "    res_year = {}\n",
    "    \n",
    "    for i in range(0,lenCol):\n",
    "        condition = data[data['column_num']==i]\n",
    "        exec((f'cate{i}= condition.iloc[:, 2].values'))\n",
    "        res_col[f'cate{i}'] = eval(f'cate{i}')\n",
    "        \n",
    "    for y in year:\n",
    "        condition = data[data['create_date']==y]\n",
    "        res_year[y] = condition.iloc[:, 2].values\n",
    "        \n",
    "    # all columns\n",
    "    titles = data.iloc[:, [2]].values\n",
    "\n",
    "    return res_col,res_year,columns,lenCol,authors,year\n",
    "\n",
    "def seg_text(data,stopwords):\n",
    "    seg_words = jieba.cut(data) # segmentation\n",
    "    filtered_words = [word for word in seg_words if word not in stopwords] # filtered stopwords\n",
    "    return filtered_words\n",
    "\n",
    "def extract_keywords(data):\n",
    "    text = ' '.join(data)  \n",
    "    keywords = jieba.analyse.extract_tags(text, topK=5, withWeight=True)\n",
    "    return keywords\n",
    "\n",
    "def reduplication(lists):\n",
    "    all_keywords = {}\n",
    "\n",
    "    for keywords in lists:\n",
    "        for keyword, weight in keywords:\n",
    "            if keyword not in all_keywords:\n",
    "                all_keywords[keyword] = weight\n",
    "            else:\n",
    "                all_keywords[keyword] += weight\n",
    "    \n",
    "    # normalize the weights\n",
    "    max_weight = max(all_keywords.values())\n",
    "    for keyword in all_keywords:\n",
    "        all_keywords[keyword] /= max_weight\n",
    "    return all_keywords\n",
    "\n",
    "def ranking_keywords(kw_list):\n",
    "    sorted_keywords = sorted(kw_list.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top 15 keywords\n",
    "    top_keywords = sorted_keywords[:15]\n",
    "    top_keywords = dict(top_keywords)\n",
    "    \n",
    "    return top_keywords\n",
    "\n",
    "def generate_wordcloud(name, lists):   \n",
    "    color_list = ['#61A3BA','#D2DE32','#A2C579']\n",
    "    sorted_lists = sorted(lists.items(), key=lambda x: x[1], reverse=True)\n",
    "    keywords = [item[0] for item in sorted_lists]\n",
    "    weights = [item[1] for item in sorted_lists]\n",
    "    wordcloud = WordCloud(font_path='simhei.ttf', width=800, height=400, background_color='white')\n",
    "    wordcloud.generate_from_frequencies(dict(zip(keywords, weights)))\n",
    "    wordcloud.recolor(color_func=lambda *args, \n",
    "                      **kwargs: '#265073' if kwargs['word'] in [item[0] for item in sorted_lists[:14]] else random.choice(color_list))    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(name, fontproperties='SimSun',size=20)\n",
    "#     plt.show()\n",
    "    \n",
    "    plt.savefig(f'{name}_wordcloud.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "def add_stop_words(stopwords,wd_list):\n",
    "    for wd in wd_list:\n",
    "        words = jieba.lcut(wd)\n",
    "        stopwords.extend(words)\n",
    "\n",
    "    return list(set(stopwords))\n",
    "\n",
    "def generate_ranking_histogram(name,keyword):\n",
    "    top_keywords = ranking_keywords(keyword)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(top_keywords.keys(), top_keywords.values())\n",
    "    plt.title(name,fontproperties='SimSun',size=20)\n",
    "    plt.xlabel(\"Keyword\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45,fontproperties='SimSun',size=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{name}_ranking.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def generate_word_frequency(name,seg):\n",
    "    word_counts = Counter(word for sublist in seg for word in sublist)\n",
    "    word_counts = word_counts.most_common(15)\n",
    "    print(name,':',word_counts)\n",
    "    words = [word for word, count in word_counts]\n",
    "    counts = [count for word, count in word_counts]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(words, counts)\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(name,fontproperties='SimSun',size=20)\n",
    "    plt.xticks(rotation=45,fontproperties='SimSun',size=15)\n",
    "#     plt.show()\n",
    "    plt.savefig(f'{name}_frequency.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    res_col,res_year,columns,lenCol,authors,year = read_data(r'.\\zhihu_data.csv')\n",
    "    \n",
    "    # initialize stopwords\n",
    "    # source from https://github.com/elephantnose/characters\n",
    "    # combinding The Chinese stop word list, HIT stop word list, \n",
    "    # Baidu stop word list, Sichuan University Machine intelligence Laboratory stop word database \n",
    "    # of four lists were merged and de-duplicated\n",
    "    stopwords = [line.strip() for line in open('stop_words.txt', encoding='UTF-8').readlines()]\n",
    "    stopwords = add_stop_words(stopwords,authors)\n",
    "    stopwords = add_stop_words(stopwords,columns)\n",
    "    \n",
    "    for j in range(0,lenCol):\n",
    "        seg_column = [seg_text(str(title), stopwords) for title in res_col[f'cate{j}']]\n",
    "        generate_word_frequency(columns[j],seg_column)\n",
    "        keyword = [extract_keywords(data) for data in seg_column]\n",
    "        keyword = reduplication(keyword)\n",
    "        all_kwds_col.update(keyword) \n",
    "        generate_wordcloud(columns[j],keyword)\n",
    "        generate_ranking_histogram(columns[j],keyword)\n",
    "        \n",
    "    stopwords = add_stop_words(stopwords,year)\n",
    "    for k in year:\n",
    "        seg_year = [seg_text(str(title), stopwords) for title in res_year[k]]\n",
    "        generate_word_frequency(k,seg_year)\n",
    "        keyword = [extract_keywords(data) for data in seg_year]\n",
    "        keyword = reduplication(keyword)\n",
    "        all_kwds_year.update(keyword) \n",
    "        generate_wordcloud(k,keyword)\n",
    "        generate_ranking_histogram(k,keyword)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d3f54",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False #Solve problems such as Chinese garbled characters\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414700ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'.\\zhihu_data.csv', encoding='gb18030')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5114db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all nan data\n",
    "data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lines where some values are nan\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check approval_num\n",
    "data[data[\"approval_num\"] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46655ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check comments_num\n",
    "data[data[\"comments_num\"] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd1148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check duplicated data\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a125d",
   "metadata": {},
   "source": [
    "### 1. Average approval_num and comments_num for different columns —— Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64dfc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by column and average the approval_num and comments_num\n",
    "grouped = data.groupby('column_name')['approval_num', 'comments_num'].mean()\n",
    "\n",
    "# Draw a histogram of approval_num\n",
    "fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "bar1 = ax1.bar(grouped.index, grouped['approval_num'], color='skyblue')\n",
    "ax1.set_xlabel('column_name',fontsize=16)\n",
    "ax1.set_ylabel('approval_num',fontsize=16)\n",
    "ax1.set_title('Average approval_num by column',fontsize=16)\n",
    "\n",
    "# Add labels to the bar chart\n",
    "for rect in bar1:\n",
    "    height = rect.get_height()\n",
    "    ax1.text(rect.get_x() + rect.get_width() / 2, height, f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Automatically adjust the display of horizontal axis labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Draw a histogram of comments_num\n",
    "fig, ax2 = plt.subplots(figsize=(15, 8))\n",
    "bar2 = ax2.bar(grouped.index, grouped['comments_num'], color='lightgreen')\n",
    "ax2.set_xlabel('column_name',fontsize=16)\n",
    "ax2.set_ylabel('comments_num',fontsize=16)\n",
    "ax2.set_title('Average comments_num by column',fontsize=16)\n",
    "\n",
    "# Add labels to the bar chart\n",
    "for rect in bar2:\n",
    "    height = rect.get_height()\n",
    "    ax2.text(rect.get_x() + rect.get_width() / 2, height, f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Automatically adjust the display of horizontal axis labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803378d",
   "metadata": {},
   "source": [
    "### 2. Total approval_num and comments_num for different columns —— Double vertical axis bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672bb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of approval_num and comments_num based on the column_name\n",
    "column_data = data.groupby('column_name')['approval_num', 'comments_num'].sum()\n",
    "\n",
    "# Create a chart with two vertical axes\n",
    "fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot a histogram of total approval points (first vertical axis)\n",
    "bar1 = ax1.bar(range(len(column_data)), column_data['approval_num'], color='skyblue')\n",
    "ax1.set_xlabel('column_name',fontsize=16)\n",
    "ax1.set_ylabel('sum of total approval_num',fontsize=16)\n",
    "\n",
    "# Plot a line chart of the total comments_num (second vertical axis)\n",
    "line1, = ax2.plot(range(len(column_data)), column_data['comments_num'], color='lightgreen', marker='o')\n",
    "ax2.set_ylabel('sum of total comments_num',fontsize=16)\n",
    "\n",
    "# Set the x-axis tick positions and labels\n",
    "ax1.set_xticks(range(len(column_data)))\n",
    "ax1.set_xticklabels(column_data.index, rotation=45)\n",
    "\n",
    "# Add labels to the bar chart\n",
    "for rect in bar1:\n",
    "    height = rect.get_height()\n",
    "    ax1.text(rect.get_x() + rect.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
    "\n",
    "# Add labels to the line chart\n",
    "for x, y in zip(range(len(column_data)), column_data['comments_num']):\n",
    "    ax2.text(x, y, f'{y}', ha='center', va='bottom')\n",
    "\n",
    "# Set chart title\n",
    "plt.title('Total approval_num and comments_num in different column_names',fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a03c84",
   "metadata": {},
   "source": [
    "### 3. The ten authors with the most approval_num —— horizontal bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in descending order by total approval_num\n",
    "top_10_authors = author_approval.sort_values('approval_num', ascending=False).head(10)\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Draw a horizontal bar chart\n",
    "bars = ax.barh(top_10_authors['author_name'][::-1], top_10_authors['approval_num'][::-1], color='orange')\n",
    "\n",
    "# Add text labels to each bar\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height() / 2, f'{int(width)}', ha='left', va='center')\n",
    "\n",
    "# Set horizontal and vertical axis labels\n",
    "ax.set_xlabel('total approval_num', fontsize=16)\n",
    "ax.set_ylabel('author_name', fontsize=16)\n",
    "\n",
    "# Set chart title\n",
    "plt.title('Top ten authors with the most approval_num', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4e372",
   "metadata": {},
   "source": [
    "### 4. The ten authors with the most comments_num —— horizontal bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in descending order by total comments_num\n",
    "top_10_authors = author_comments.sort_values('comments_num', ascending=False).head(10)\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Draw a horizontal bar chart\n",
    "bars = ax.barh(top_10_authors['author_name'][::-1], top_10_authors['comments_num'][::-1], color='pink')\n",
    "\n",
    "# Add text labels to each bar\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height() / 2, f'{int(width)}', ha='left', va='center')\n",
    "\n",
    "# Set horizontal and vertical axis labels\n",
    "ax.set_xlabel('total comments_num', fontsize=16)\n",
    "ax.set_ylabel('author_name', fontsize=16)\n",
    "\n",
    "# Set chart title\n",
    "plt.title('Top ten authors with the most comments_num', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6810cc7",
   "metadata": {},
   "source": [
    "### 5. Gender ratio of top ten authors with most approval_num —— Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group according to the column_name and calculate the top ten authors with the most approval_num for each column name\n",
    "top_10_authors = data.groupby('column_name').apply(lambda x: x.nlargest(10, 'approval_num'))\n",
    "\n",
    "# Statistics of the gender ratio of the top ten authors of each column_name\n",
    "gender_counts = top_10_authors['author_sex'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Draw a pie chart\n",
    "ax.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Set chart title\n",
    "plt.title('Gender ratio of top ten authors with most approval_num')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531d154",
   "metadata": {},
   "source": [
    "### 6. Gender ratio of top ten authors with most comments_num —— Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae42ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group according to the column_name and calculate the top ten authors with the most comments_num for each column name\n",
    "top_10_authors = data.groupby('column_name').apply(lambda x: x.nlargest(10, 'comments_num'))\n",
    "\n",
    "# Statistics of the gender ratio of the top ten authors of each column_name\n",
    "gender_counts = top_10_authors['author_sex'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Custom color list\n",
    "colors = ['lightgreen', 'lightcoral']\n",
    "\n",
    "# Draw a pie chart and set colors\n",
    "ax.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "\n",
    "# Set chart title\n",
    "plt.title('Gender ratio of top ten authors with most comments_num')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a092fb",
   "metadata": {},
   "source": [
    "### 7. Analyze changes in the approval_num and comments_num over time —— Area Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde20c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Convert create_date and update_date to date type\n",
    "data['create_date'] = pd.to_datetime(data['create_date'])\n",
    "data['update_date'] = pd.to_datetime(data['update_date'])\n",
    "\n",
    "# Accurate date to month\n",
    "data['create_month'] = data['create_date'].dt.to_period('M').astype(str)\n",
    "data['update_month'] = data['update_date'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Analyze the approval_num and comments_num based on create_date\n",
    "approval_by_create_month = data.groupby('create_month')['approval_num'].sum()\n",
    "comments_by_create_month = data.groupby('create_month')['comments_num'].sum()\n",
    "\n",
    "# Analyze the approval_num and comments_num based on update_date\n",
    "approval_by_update_date = data.groupby('update_month')['approval_num'].sum()\n",
    "comments_by_update_date = data.groupby('update_month')['comments_num'].sum()\n",
    "\n",
    "# Create line and area charts\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "# Plot line and area charts of approval_num as a function of create_date\n",
    "ax[0].plot(approval_by_create_month.index, approval_by_create_month, color='skyblue', linewidth=2, label='approval_num')\n",
    "ax[0].fill_between(approval_by_create_month.index, approval_by_create_month, color='skyblue', alpha=0.2)\n",
    "ax[0].set_xlabel('create_month')\n",
    "ax[0].set_ylabel('approval_num')\n",
    "ax[0].set_title('approval_num changes according to create_month')\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot line and area charts of comments_num as a function of create_date\n",
    "ax[1].plot(comments_by_create_month.index, comments_by_create_month, color='lightgreen', linewidth=2, label='comments_num')\n",
    "ax[1].fill_between(comments_by_create_month.index, comments_by_create_month, color='lightgreen', alpha=0.2)\n",
    "ax[1].set_xlabel('create_month')\n",
    "ax[1].set_ylabel('comments_num')\n",
    "ax[1].set_title('comments_num changes according to create_month')\n",
    "ax[1].legend()\n",
    "\n",
    "# Set horizontal axis label spacing\n",
    "for axes in ax:\n",
    "    axes.set_xticks(axes.get_xticks()[::6])  # Display every 6 labels\n",
    "\n",
    "# Adjust the spacing between subimages\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830043ef",
   "metadata": {},
   "source": [
    "### 8. Author activity analysis —— Lollipop Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3179ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of publications by each author\n",
    "author_counts = data['author_name'].value_counts()\n",
    "\n",
    "# Sort authors by number of publications\n",
    "sorted_authors = author_counts.sort_values(ascending=False)\n",
    "\n",
    "# Extract the top 10 most active authors and the corresponding number of publications\n",
    "top_authors = sorted_authors.head(10)\n",
    "top_author_names = top_authors.index\n",
    "top_author_counts = top_authors.values\n",
    "\n",
    "# Create a Lollipop chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Draw vertical lines\n",
    "ax.vlines(x=top_author_names, ymin=0, ymax=top_author_counts, color='firebrick', alpha=0.7, linewidth=2)\n",
    "\n",
    "# Draw dots\n",
    "ax.scatter(x=top_author_names, y=top_author_counts, color='firebrick', s=75, alpha=0.7)\n",
    "\n",
    "# Set horizontal axis labels and titles\n",
    "ax.set_xlabel('author_name')\n",
    "ax.set_ylabel('the number of publications')\n",
    "ax.set_title('Top 10 Authors by the number of publications')\n",
    "\n",
    "# Rotate horizontal axis labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Invert the vertical axis so that authors with the highest number of publications are at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Adjust the vertical axis scale range\n",
    "ax.set_ylim([0, top_author_counts.max() * 1.1])\n",
    "\n",
    "# Hide right and top borders\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Show data labels\n",
    "for i in range(len(top_author_names)):\n",
    "    ax.text(top_author_names[i], top_author_counts[i], str(top_author_counts[i]), ha='center', va='bottom')\n",
    "\n",
    "# Show chart\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
